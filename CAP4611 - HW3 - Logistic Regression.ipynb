{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Artful-Donut/MachineLearning-Practice/blob/main/CAP4611%20-%20HW3%20-%20Logistic%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00bf530",
      "metadata": {
        "id": "c00bf530"
      },
      "source": [
        "# Homework 3\n",
        "\n",
        "This project asks you to perform various experiments with regression. The dataset we are using is taken from a real estate dataset (also used in HW2).\n",
        "\n",
        "You will write code and discussion texts into code and text cells in this notebook.\n",
        "\n",
        "If a block starts with TODO:, this means that you need to write something there.\n",
        "\n",
        "Some code had been written for you to guide the project. Don't change the already written code.\n",
        "\n",
        "## Grading\n",
        "Each subproblem is worth 10 pt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a440a191",
      "metadata": {
        "id": "a440a191"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sklearn as sk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "691d1a9f",
      "metadata": {
        "id": "691d1a9f"
      },
      "source": [
        "## Setup for the first part of the homework\n",
        "\n",
        "For problems P1 to P6 we are using a simple dataset where we extract one\n",
        "explanatory variable ``sq_mt_built`` to predict the price of the house ``buy_price``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "902ccefe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "902ccefe",
        "outputId": "e830d15c-64fe-40ed-9747-476829b84773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "The lenght 21742\n",
            "The columns of the database Index(['Unnamed: 0', 'id', 'title', 'subtitle', 'sq_mt_built', 'sq_mt_useful',\n",
            "       'n_rooms', 'n_bathrooms', 'n_floors', 'sq_mt_allotment', 'latitude',\n",
            "       'longitude', 'raw_address', 'is_exact_address_hidden', 'street_name',\n",
            "       'street_number', 'portal', 'floor', 'is_floor_under', 'door',\n",
            "       'neighborhood_id', 'operation', 'rent_price', 'rent_price_by_area',\n",
            "       'is_rent_price_known', 'buy_price', 'buy_price_by_area',\n",
            "       'is_buy_price_known', 'house_type_id', 'is_renewal_needed',\n",
            "       'is_new_development', 'built_year', 'has_central_heating',\n",
            "       'has_individual_heating', 'are_pets_allowed', 'has_ac',\n",
            "       'has_fitted_wardrobes', 'has_lift', 'is_exterior', 'has_garden',\n",
            "       'has_pool', 'has_terrace', 'has_balcony', 'has_storage_room',\n",
            "       'is_furnished', 'is_kitchen_equipped', 'is_accessible',\n",
            "       'has_green_zones', 'energy_certificate', 'has_parking',\n",
            "       'has_private_parking', 'has_public_parking',\n",
            "       'is_parking_included_in_price', 'parking_price', 'is_orientation_north',\n",
            "       'is_orientation_west', 'is_orientation_south', 'is_orientation_east'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "df = pd.read_csv('gdrive/My Drive/UCF/Spring Semester 2025/CAP4611/houses_Madrid.csv')\n",
        "\n",
        "# df = pd.read_csv(\"houses_Madrid.csv\")\n",
        "print(f\"The lenght {len(df.index)}\")\n",
        "print(f\"The columns of the database {df.columns}\")\n",
        "df[[\"sq_mt_built\", \"buy_price\"]].plot.scatter(x=\"sq_mt_built\", y=\"buy_price\")\n",
        "## FIXME: add here the creation of the training data and test data\n",
        "\n",
        "df_shuffled = df.sample(frac=1) # shuffle the rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54bf2ec2",
      "metadata": {
        "id": "54bf2ec2"
      },
      "outputs": [],
      "source": [
        "x = df_shuffled[\"sq_mt_built\"].to_numpy(dtype=np.float64)\n",
        "y = df_shuffled[\"buy_price\"].to_numpy(dtype=np.float64)\n",
        "training_data_x = x[:16000]\n",
        "training_data_y = y[:16000]\n",
        "test_data_x = x[16000:]\n",
        "test_data_y = y[16000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8bfd4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d8bfd4d",
        "outputId": "6c3a6a7d-3389-436c-cc1b-c35fb7fce3be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([320000., 359900., 120000., ..., 285000., 890000., 180000.])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "training_data_y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_x = np.nan_to_num(training_data_x, nan = 0.0)\n",
        "training_data_y = np.nan_to_num(training_data_y, nan = 0.0)\n",
        "\n",
        "test_data_x = np.nan_to_num(test_data_x, nan = 0.0)\n",
        "test_data_y = np.nan_to_num(test_data_y, nan = 0.0)"
      ],
      "metadata": {
        "id": "oz4zw8WvZimP"
      },
      "id": "oz4zw8WvZimP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1c63bf75",
      "metadata": {
        "id": "1c63bf75"
      },
      "source": [
        "## P1: Loss function\n",
        "Implement a root-mean-square error (RMSE) loss function between the prediction $\\hat{y}$ and $y$ value using Python operations. Run some experiments to validate that this works as expected.\n",
        "Then, look up the same in the sklearn library\n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "and implement it based on what is there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d0d477",
      "metadata": {
        "id": "66d0d477"
      },
      "outputs": [],
      "source": [
        "# TODO: implement the loss function here using Python math ops and sklearn\n",
        "def loss_RMSE(y, yhat):\n",
        "    se = 0\n",
        "    for i in range(len(y)):\n",
        "        se += (y[i] - yhat[i]) ** 2\n",
        "    m = se / len(y)\n",
        "    return np.sqrt(m)\n",
        "\n",
        "def loss_RMSE_sk(y, yhat):\n",
        "    return sk.metrics.root_mean_squared_error(y, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a723623d",
      "metadata": {
        "id": "a723623d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937bfe65-f049-4fa0-8b66-9c0976b1e8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss when y and yhat are the same\n",
            "Loss_RMSE: 0.0\n",
            "Loss_RMSE_sk: 0.0\n",
            "Loss with buy price * 100 + 0\n",
            "Loss_RMSE: 100911770.24323006\n",
            "Loss_RMSE_sk: 100911770.24322882\n"
          ]
        }
      ],
      "source": [
        "# TODO: Now, run some experiments with your function, with the one taken with sklearn\n",
        "# Compare their outputs.\n",
        "\n",
        "y1 = np.empty(10); y1.fill(10)\n",
        "\n",
        "print(\"Loss when y and yhat are the same\")\n",
        "print(f\"Loss_RMSE: {loss_RMSE(y1, y1)}\")\n",
        "print(f\"Loss_RMSE_sk: {loss_RMSE_sk(y1, y1)}\")\n",
        "\n",
        "y2 = []\n",
        "for i in y:\n",
        "  y2.append(i * 100)\n",
        "\n",
        "\n",
        "# Looks like they're about the same. Yipee!!\n",
        "print(\"Loss with buy price * 100 + 0\")\n",
        "print(f\"Loss_RMSE: {loss_RMSE(y, y2)}\")\n",
        "print(f\"Loss_RMSE_sk: {loss_RMSE_sk(y, y2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0548dea",
      "metadata": {
        "id": "e0548dea"
      },
      "source": [
        "## P2: Implement a linear predictor\n",
        "Implement a function of type ``predict(x, theta) --> y_hat`` which implements a linear model of the type $\\hat{y} = \\theta_1 \\cdot x + \\theta_0$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b91956b",
      "metadata": {
        "id": "1b91956b"
      },
      "outputs": [],
      "source": [
        "# TODO: implement the predictor function here\n",
        "def predict(x, theta):\n",
        "    y_hat = (x * theta[1]) + theta[0]\n",
        "    return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7af53924",
      "metadata": {
        "id": "7af53924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04505e1e-9d1c-4c3e-b793-51ded3cac9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing out prediction function\n",
            "\n",
            "1x + 0\n",
            "0 1 2 3 4 5 6 7 8 9 \n",
            "5x + 0\n",
            "0 5 10 15 20 25 30 35 40 45 \n",
            "1x + 1\n",
            "1 2 3 4 5 6 7 8 9 10 \n",
            "0x + 1\n",
            "1 1 1 1 1 1 1 1 1 1 \n",
            "10x + 2\n",
            "2 12 22 32 42 52 62 72 82 92 "
          ]
        }
      ],
      "source": [
        "# TODO: now, run some experiments with it\n",
        "print(\"Testing out prediction function\")\n",
        "tuples = [[0,1], [0,5], [1,1], [1,0], [2,10]]\n",
        "\n",
        "for t in tuples:\n",
        "  print()\n",
        "  print(f\"{t[1]}x + {t[0]}\")\n",
        "  for i in range(10):\n",
        "    print(predict(i, t), end=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5fcd1c6",
      "metadata": {
        "id": "a5fcd1c6"
      },
      "source": [
        "## P3: Grid search\n",
        "Implement a function ``grid_search()`` which returns an estimate of the best $\\theta$ by trying out all the combinations of possibilities on a grid and returning the values that give you the most values.\n",
        "gridx and gridy define the range of numbers that we want to explore. For instance, grid0 might be [0, 0.25, 0.5, 0.75, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9663e31d",
      "metadata": {
        "id": "9663e31d"
      },
      "outputs": [],
      "source": [
        "# TODO: implement the grid search function here\n",
        "def grid_search(training_data_x, training_data_y, grid0, grid1):\n",
        "    theta = [0, 0]\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for i in grid0:\n",
        "      for j in grid1:\n",
        "        n_theta = [i, j]\n",
        "        predict_y = []\n",
        "        for data in training_data_x:\n",
        "          predict_y.append(predict(data, n_theta))\n",
        "\n",
        "        loss = loss_RMSE_sk(training_data_y, predict_y)\n",
        "\n",
        "        if(loss < best_loss):\n",
        "          # print(f\"Theta {n_theta}, Loss: {loss}, Prev_Loss: {prev_loss}\")\n",
        "          theta = n_theta\n",
        "          best_loss = loss\n",
        "\n",
        "        prev_loss = loss\n",
        "\n",
        "\n",
        "    return theta, best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65e10363",
      "metadata": {
        "id": "65e10363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2655bd82-9e61-4079-d020-c607fb6c4e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best theta: [800.0, 4500.0], Loss: 514472.10718100227\n",
            "Time taken: 0.2792384624481201\n",
            "With the test set:\n",
            "Loss: 485564.60711680574\n"
          ]
        }
      ],
      "source": [
        "# TODO: run some experiments with grid_search\n",
        "# Define some grid values. Train it on the data set. Test it on the test set.\n",
        "# Print the loss on the data set and the test set. Measure and print how long the training takes.\n",
        "import time\n",
        "\n",
        "begin = time.time()\n",
        "\n",
        "gridx = [200.0, 300.0, 500.0, 800.0, 1000.0]\n",
        "gridy = [3000.0, 3700.0, 4000.0, 4500.0, 4600.0]\n",
        "\n",
        "best_theta, loss = grid_search(training_data_x, training_data_y, gridx, gridy)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Best theta: {best_theta}, Loss: {loss}\")\n",
        "print(f\"Time taken: {end-begin}\")\n",
        "\n",
        "print(\"With the test set:\")\n",
        "prediction = []\n",
        "for data in test_data_x:\n",
        "  prediction.append(predict(data, best_theta))\n",
        "\n",
        "print(f\"Loss: {loss_RMSE_sk(test_data_y, prediction)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "716ed9d9",
      "metadata": {
        "id": "716ed9d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c9b150-d091-433a-95da-3a3de5e9fb75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 100, 200, 300, 400], [1000, 1100, 1200, 1300, 1400], [2000, 2100, 2200, 2300, 2400], [3000, 3100, 3200, 3300, 3400], [4000, 4100, 4200, 4300, 4400]]\n",
            "[[0, 200, 400, 600, 800], [5000, 5200, 5400, 5600, 5800], [10000, 10200, 10400, 10600, 10800], [15000, 15200, 15400, 15600, 15800], [20000, 20200, 20400, 20600, 20800]]\n",
            "Best theta: [0, 5000], Loss: 523784.7090187539\n",
            "Time taken: 0.146148681640625\n",
            "Best grid: [[0, 100, 200, 300, 400], [5000, 5200, 5400, 5600, 5800]]\n",
            "With the test set:\n",
            "Loss: 502409.35191633995\n"
          ]
        }
      ],
      "source": [
        "# TODO: repeat the experimentation from above with different grids.\n",
        "# Finally, print the grid that provides the best value while still running faster\n",
        "# than 10 seconds.\n",
        "\n",
        "gridx = []\n",
        "\n",
        "for i in range(5):\n",
        "  new_grid = []\n",
        "  for j in range(5):\n",
        "    new_grid.append(i * 1000 + j * 100)\n",
        "  gridx.append(new_grid)\n",
        "print(gridx)\n",
        "gridy = []\n",
        "\n",
        "for i in range(5):\n",
        "  new_grid = []\n",
        "  for j in range(5):\n",
        "    new_grid.append(i * 5000 + j * 200)\n",
        "  gridy.append(new_grid)\n",
        "print(gridy)\n",
        "\n",
        "\n",
        "best_loss = loss = float('inf')\n",
        "best_grid = []\n",
        "best_theta = []\n",
        "\n",
        "for i in gridx:\n",
        "  for j in gridy:\n",
        "    begin = time.time()\n",
        "    theta, loss = grid_search(training_data_x, training_data_y, i, j)\n",
        "    end = time.time()\n",
        "    elapsed = end - begin\n",
        "    if(elapsed < 10 and loss < best_loss):\n",
        "      best_theta = theta\n",
        "      best_loss = loss\n",
        "      best_grid = [i, j]\n",
        "\n",
        "print(f\"Best theta: {best_theta}, Loss: {best_loss}\")\n",
        "print(f\"Time taken: {end-begin}\")\n",
        "print(f\"Best grid: {best_grid}\")\n",
        "\n",
        "print(\"With the test set:\")\n",
        "prediction = []\n",
        "for data in test_data_x:\n",
        "  prediction.append(predict(data, best_theta))\n",
        "\n",
        "print(f\"Loss: {loss_RMSE_sk(test_data_y, prediction)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c46a9f4",
      "metadata": {
        "id": "4c46a9f4"
      },
      "source": [
        "## P4: Random search\n",
        "Implement a function that returns the estimate for the best $\\theta$ by trying out random\n",
        "$\\theta=[\\theta_0, \\theta_1]$ values, and returning the one that minimizes the error on the training set passed to it. The number of tries is described in the ``trials`` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc373403",
      "metadata": {
        "id": "cc373403"
      },
      "outputs": [],
      "source": [
        "# TODO: implement the random search function here\n",
        "def random_search(training_data_x, training_data_y, trials):\n",
        "    theta = [0, 0]\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for i in range(trials):\n",
        "      n_theta = [np.random.random() * training_data_y.max() / 10, np.random.random() * training_data_y.max() / 10]\n",
        "\n",
        "      predict_y = []\n",
        "      for data in training_data_x:\n",
        "          predict_y.append(predict(data, n_theta))\n",
        "\n",
        "      loss = loss_RMSE_sk(training_data_y, predict_y)\n",
        "\n",
        "      if(loss < best_loss):\n",
        "        theta = n_theta\n",
        "        best_loss = loss\n",
        "\n",
        "    return theta, best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294dde6b",
      "metadata": {
        "id": "294dde6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724acb56-00bb-4d2b-9efe-8cab6cf01a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best theta: [79825.40947127058, 4005.45263693739], Loss: 518525.13847652735\n",
            "Time taken to train: 31.871904134750366\n",
            "With the test set:\n",
            "Loss: 486697.65856209025\n"
          ]
        }
      ],
      "source": [
        "# TODO: run some experiments with random_search\n",
        "# Choose some value for trial. Train it on the data set. Test it on the test set.\n",
        "# Print the loss on the data set and the test set. Measure and print how long the training takes.\n",
        "\n",
        "begin = time.time()\n",
        "\n",
        "best_theta, loss = random_search(training_data_x, training_data_y, 5000)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Best theta: {best_theta}, Loss: {loss}\")\n",
        "print(f\"Time taken to train: {end-begin}\")\n",
        "\n",
        "\n",
        "print(\"With the test set:\")\n",
        "prediction = []\n",
        "for data in test_data_x:\n",
        "  prediction.append(predict(data, best_theta))\n",
        "\n",
        "print(f\"Loss: {loss_RMSE_sk(test_data_y, prediction)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e169df",
      "metadata": {
        "id": "85e169df"
      },
      "source": [
        "## P5: Improvements\n",
        "Propose an improvement to the algorithms you have implemented for 3 and 4 and show that with your improvement, the performance is better than the original. Some examples of what you might try:\n",
        "* Choose values for $\\theta_0$ and $\\theta_1$ on a non-uniform grid\n",
        "* First find one of them, and fix it, and then refine on the other one\n",
        "* For random: sample according to a non-uniform distribution\n",
        "* First use a low resolution search to find the approximate values of  $\\theta_0$ and $\\theta_1$, then search for a more precise value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb552fcc",
      "metadata": {
        "id": "bb552fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fccff362-67e3-4d88-fc2d-42f7fcc653cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([4329, 2907, 1632, 2949, 5113, 3658, 6044, 6231, 7191, 3307]), array([7874, 6265, 6499, 1616, 3623, 8877, 8676,  425, 3240, 5622, 1716,\n",
            "       6005, 1107, 9833, 2182]), array([7439,  306, 6373]), array([7754, 5568, 8553, 7870, 1686]), array([9465])]\n",
            "[array([9233, 1211, 2473, 8722, 9637, 4080, 2068, 2470, 4573, 7860]), array([5058, 9310, 4292]), array([1492, 9308, 5019, 9777,  546, 4383, 7523]), array([ 966, 8630, 6633,  497,   58, 6772, 6539])]\n",
            "Best theta: [306, 4573], Loss: 514681.7087867009\n",
            "Time taken: 0.05485200881958008\n",
            "Best grid: [array([7439,  306, 6373]), array([9233, 1211, 2473, 8722, 9637, 4080, 2068, 2470, 4573, 7860])]\n"
          ]
        }
      ],
      "source": [
        "# TODO: implement your improvements here\n",
        "gridx = [np.random.randint(0,10000, (10)), np.random.randint(0,10000, (15)), np.random.randint(0,10000, (3)), np.random.randint(0,10000, (5)), np.random.randint(0,10000, (1))]\n",
        "print(gridx)\n",
        "gridy = [np.random.randint(0,10000, (10)), np.random.randint(0,10000, (3)), np.random.randint(0,10000, (7)), np.random.randint(0,10000, (7))]\n",
        "print(gridy)\n",
        "\n",
        "\n",
        "best_loss = loss = float('inf')\n",
        "best_grid = []\n",
        "best_theta = []\n",
        "\n",
        "for i in gridx:\n",
        "  for j in gridy:\n",
        "    begin = time.time()\n",
        "    theta, loss = grid_search(training_data_x, training_data_y, i, j)\n",
        "    end = time.time()\n",
        "    elapsed = end - begin\n",
        "    if(elapsed < 10 and loss < best_loss):\n",
        "      best_theta = theta\n",
        "      best_loss = loss\n",
        "      best_grid = [i, j]\n",
        "\n",
        "print(f\"Best theta: {best_theta}, Loss: {best_loss}\")\n",
        "print(f\"Time taken: {end-begin}\")\n",
        "print(f\"Best grid: {best_grid}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d1dd74e",
      "metadata": {
        "id": "4d1dd74e"
      },
      "source": [
        "TODO: Describe in one paragraph the conclusions you have drawn from your improvement experiments\n",
        "\n",
        "---\n",
        "\n",
        "I decided to implement my grid_search() function with non-uniform grids with the np.random.randint() function. I believe I used fewer values for the grids, which is why the time taken for this is about halved- but even so, the values that the grid_search() found ended up having a better loss value than the uniform grids. In short, I think implementing grid search with non-uniform grids is a much better method of finding theta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c0d4e8",
      "metadata": {
        "id": "c5c0d4e8"
      },
      "source": [
        "## P6: Using the sklearn library for linear regression\n",
        "\n",
        "Use ``sklearn.linear_model.LinearRegression`` to solve the same problem you previously solved using the grid search and random search.\n",
        "\n",
        "Compare the returned values with what you have achieved. Compare the parameters that had been found to the parameters you have found. Compare the speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "136e4f63",
      "metadata": {
        "id": "136e4f63"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement here\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def linear_regression(training_data_x, training_data_y, test_data_x, test_data_y):\n",
        "    training_data_x = training_data_x.reshape(-1, 1)\n",
        "    test_data_x = test_data_x.reshape(-1, 1)\n",
        "\n",
        "    model = sk.linear_model.LinearRegression()\n",
        "    model.fit(training_data_x, training_data_y)\n",
        "    return model.predict(test_data_x), test_data_y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2dc65e",
      "metadata": {
        "id": "8b2dc65e"
      },
      "source": [
        "TODO: discuss the performance of the sklearn library implementation, compared to what you implemented.\n",
        "\n",
        "---\n",
        "\n",
        "Implementing the sklearn library to fit the model was a lot faster and more accurate than my implementations of grid search and random search. Grid search and Random search took seconds, while using sklearn took less than a second.\n",
        "\n",
        "The sklearn library's effectiveness was comparable to the effectiveness of Grid Search, though (I ended up using random values for my grids, but the point still stands, I would think). Random search, however, lagged behind in effectiveness (this makes sense, however, as my interval for random search was quite large, so the chance of bumping into the optimal value was low). It also took longer, though I believe my implementation of random search involved more steps than my implementation of grid search did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1268d33c",
      "metadata": {
        "id": "1268d33c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cdbf66-c1f4-4897-8964-48d46227ab8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effectiveness of Model:\n",
            "Loss: 493574.85951772565\n",
            "Time taken: 0.27983665466308594\n"
          ]
        }
      ],
      "source": [
        "# TODO: Run performance experiments here.\n",
        "import time\n",
        "\n",
        "begin = time.time()\n",
        "\n",
        "print(\"Effectiveness of Model:\")\n",
        "predict, test_y = linear_regression(training_data_x, training_data_y, test_data_x, test_data_y)\n",
        "print(f\"Loss: {loss_RMSE_sk(test_y, predict)}\")\n",
        "\n",
        "# store end time\n",
        "end = time.time()\n",
        "print(f\"Time taken: {end-begin}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39cba7e7",
      "metadata": {
        "id": "39cba7e7"
      },
      "source": [
        "# Setup for the second part of the project\n",
        "For the questions P7-P10 we use linear regression on a multivariate setting. This time, there are 7 explanatory variables: ``sq_mt_built``, ``n_rooms``, ``n_bathrooms``, ``is_renewal_needed``, ``is_new_development`` and ``has_fitted_wardrobes``.\n",
        "\n",
        "We will first create the training and test data while doing some minimal data cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f68a641",
      "metadata": {
        "id": "5f68a641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6278661-dfc8-460a-8cd3-93679bb5d494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-abe5b5c90550>:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_shuffled[\"has_individual_heating\"] = df_shuffled[\"has_individual_heating\"].fillna(False)\n",
            "<ipython-input-17-abe5b5c90550>:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_shuffled[\"is_new_development\"] = df_shuffled[\"is_new_development\"].fillna(False)\n",
            "<ipython-input-17-abe5b5c90550>:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_shuffled[\"has_fitted_wardrobes\"] = df_shuffled[\"has_fitted_wardrobes\"].fillna(False)\n"
          ]
        }
      ],
      "source": [
        "# replacing the NA values with some sensible defaults\n",
        "# the way I was investigating these is by printing\n",
        "#    df[\"has_individual_heeating\"].value_counts(dropna=False) etc\n",
        "df_shuffled[\"has_individual_heating\"] = df_shuffled[\"has_individual_heating\"].fillna(False)\n",
        "df_shuffled[\"n_bathrooms\"] = df_shuffled[\"n_bathrooms\"].fillna(1)\n",
        "df_shuffled[\"has_individual_heating\"] = df_shuffled[\"has_individual_heating\"].fillna(False)\n",
        "df_shuffled[\"is_new_development\"] = df_shuffled[\"is_new_development\"].fillna(False)\n",
        "df_shuffled[\"has_fitted_wardrobes\"] = df_shuffled[\"has_fitted_wardrobes\"].fillna(False)\n",
        "\n",
        "xfields = [\"sq_mt_built\", \"n_rooms\", \"n_bathrooms\", \"has_individual_heating\", \\\n",
        "           \"is_renewal_needed\", \"is_new_development\", \"has_fitted_wardrobes\"]\n",
        "\n",
        "x = df_shuffled[xfields].to_numpy(dtype=np.float64)\n",
        "y = df_shuffled[\"buy_price\"].to_numpy(dtype=np.float64)\n",
        "training_data_x = x[:16000]\n",
        "training_data_y = y[:16000]\n",
        "test_data_x = x[16000:]\n",
        "test_data_y = y[16000:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_x\n",
        "\n",
        "training_data_x = np.nan_to_num(training_data_x, nan = 0.0)\n",
        "training_data_y = np.nan_to_num(training_data_y, nan = 0.0)\n",
        "test_data_x = np.nan_to_num(test_data_x, nan = 0.0)\n",
        "test_data_y = np.nan_to_num(test_data_y, nan = 0.0)"
      ],
      "metadata": {
        "id": "X8RfNssOKvvC"
      },
      "id": "X8RfNssOKvvC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "848d0c5b",
      "metadata": {
        "id": "848d0c5b"
      },
      "source": [
        "## P7: Grid search for multiple variables\n",
        "Implement the linear predictor model for multiple variables. Note that this time ``x`` will be an array of 7 values, and ``theta`` will be an array of 8 values.\n",
        "\n",
        "Then, implement a grid search function (similar to P3) but this time for the 7 explanatory variables. Pass the grids as an array into the grid variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde6d4ce",
      "metadata": {
        "id": "bde6d4ce"
      },
      "outputs": [],
      "source": [
        "# TODO: implement the predictor function here\n",
        "def predict_multi(x, theta):\n",
        "    y_hat = []\n",
        "    for data in x:\n",
        "        n_yhat = 0\n",
        "        for i in range(7):\n",
        "          n_yhat += data[i] * theta[i+1]\n",
        "        n_yhat += theta[0]\n",
        "        y_hat.append(n_yhat)\n",
        "\n",
        "    y_hat += theta[0]\n",
        "    return y_hat\n",
        "\n",
        "# TODO: implement the grid search function here\n",
        "def grid_search(training_data_x, training_data_y, grids):\n",
        "    theta = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for t1 in grids[0]:\n",
        "      for t2 in grids[1]:\n",
        "        for t3 in grids[2]:\n",
        "          for t4 in grids[3]:\n",
        "            for t5 in grids[4]:\n",
        "              for t6 in grids[5]:\n",
        "                for t7 in grids[6]:\n",
        "                  for t8 in grids[7]:\n",
        "                    n_theta = [t1, t2, t3, t4, t5, t6, t7, t8]\n",
        "\n",
        "                    predict_y = predict_multi(training_data_x, n_theta)\n",
        "                    loss = loss_RMSE_sk(training_data_y, predict_multi(training_data_x, predict_y))\n",
        "\n",
        "                    if(best_loss > loss):\n",
        "                        theta = n_theta\n",
        "                        best_loss = loss\n",
        "\n",
        "    return theta, best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080d821a",
      "metadata": {
        "id": "080d821a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f531181c-04d2-4997-cc05-0bedd6c3e445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([4567, 5392]), array([7903, 3596]), array([2165, 7185]), array([7858, 6057]), array([2747, 9071]), array([4244, 6394]), array([5662, 2772]), array([2707,  123])]\n",
            "Training Time: 29.504361391067505\n",
            "Best Theta: [4567, 3596, 2165, 6057, 2747, 4244, 5662, 123], Best Loss: 52733504.24062279\n",
            "Loss: 511711.10092462436\n"
          ]
        }
      ],
      "source": [
        "# TODO: run experiments with your implementation for the grid search\n",
        "import time\n",
        "grids = []\n",
        "\n",
        "for i in range(8):\n",
        "  grids.append(np.random.randint(0,10000, (2)))\n",
        "print(grids)\n",
        "\n",
        "begin = time.time()\n",
        "best_theta, loss = grid_search(training_data_x, training_data_y, grids)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Training Time: {end - begin}\")\n",
        "print(f\"Best Theta: {best_theta}, Best Loss: {loss}\")\n",
        "\n",
        "print(f\"Loss: {loss_RMSE(predict_multi(test_data_x, best_theta), test_data_y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab609edb",
      "metadata": {
        "id": "ab609edb"
      },
      "source": [
        "TODO: describe here your experiences with implementing this problem, conclusions you draw.\n",
        "\n",
        "---\n",
        "\n",
        "The implementation is relatively simple in logic, and I was able to get a comparable loss to the simple regression trials.\n",
        "\n",
        "However... the amount of iterations needed to calculate grid_search is n^m, where n is the amount of grids and m is the size of those grids. My grids only had 2 values each, but it took nearly 30 seconds to train the model. I shiver to think about how much it would scale if I gave grids more values...\n",
        "\n",
        "This is computationally expensive and unreasonable for very large datasets (and it took forever to run).\n",
        "\n",
        "So while grid search was very thorough, I would not use it for a dataset like the one used for this homework."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "020b814a",
      "metadata": {
        "id": "020b814a"
      },
      "source": [
        "## P8: Random search for multiple variables\n",
        "Implement the random search technique for the multiple variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f3b832",
      "metadata": {
        "id": "37f3b832"
      },
      "outputs": [],
      "source": [
        "# TODO: implement the random seeach function here\n",
        "def random_search(training_data_x, training_data_y):\n",
        "    best_theta = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    # choosing an arbitrary amount of iterations\n",
        "    for i in range(200):\n",
        "      theta = np.random.randint(0, training_data_y.max() / 2, (8))\n",
        "      predict_y = predict_multi(training_data_x, theta)\n",
        "      loss = loss_RMSE_sk(training_data_y, predict_y)\n",
        "\n",
        "      if(best_loss > loss):\n",
        "        best_loss = loss\n",
        "        best_theta = theta\n",
        "\n",
        "    return best_theta, best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c553a29d",
      "metadata": {
        "id": "c553a29d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7a9b82-4f7b-45aa-cfea-947d8b667991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 0\n",
            "Training Time: 14.661410570144653\n",
            "Best Iteration Theta: [2410452   69177  114802 1437414  745983 2106382  386071 2657910], Best Iteration Loss: 22614474.3985224\n",
            "Test 1\n",
            "Training Time: 14.805427551269531\n",
            "Best Iteration Theta: [1459207   36987  794168  131108  176900 1918216 4332693  901609], Best Iteration Loss: 12845732.4991373\n",
            "Test 2\n",
            "Training Time: 14.970728158950806\n",
            "Best Iteration Theta: [3009205   92410 1599585  317071  274342 4093512 1913518 1585369], Best Iteration Loss: 29783818.209338468\n",
            "Test 3\n",
            "Training Time: 14.746150016784668\n",
            "Best Iteration Theta: [ 490229   74248  238516 1460706  650961 3991826 3571381 2979060], Best Iteration Loss: 21394972.223238703\n",
            "Test 4\n",
            "Training Time: 14.708160161972046\n",
            "Best Iteration Theta: [2406869   10246 2081199  528632 1205144 1909153 1076554 2254712], Best Iteration Loss: 15999965.693307403\n",
            "Test 5\n",
            "Training Time: 14.731117486953735\n",
            "Best Iteration Theta: [1985295   23109  513759 2043477 3969399 1227428 2203132  600484], Best Iteration Loss: 16042475.144710014\n",
            "Test 6\n",
            "Training Time: 14.842196226119995\n",
            "Best Iteration Theta: [ 226388   69352 2013677 1769943 1234854  536793 3642161 1462060], Best Iteration Loss: 25066760.50080146\n",
            "Test 7\n",
            "Training Time: 14.606030702590942\n",
            "Best Iteration Theta: [3118401   62148 3711790  805603 2899853 3780171 4311899 1976022], Best Iteration Loss: 33641408.722071715\n",
            "Test 8\n",
            "Training Time: 14.812866926193237\n",
            "Best Iteration Theta: [2328893   51491  483421  812624 2693733 1170849 1183046 2807935], Best Iteration Loss: 19561850.356770985\n",
            "Test 9\n",
            "Training Time: 14.99002456665039\n",
            "Best Iteration Theta: [1526355    7547  313408  818878 4185962 2638638 1234357 1669928], Best Iteration Loss: 10023048.082866171\n",
            "Best Theta: [1526355    7547  313408  818878 4185962 2638638 1234357 1669928], Best Loss: 10023048.082866171\n",
            "Testing:\n",
            "Loss: 10085105.112825563\n"
          ]
        }
      ],
      "source": [
        "# TODO: run experiments with your implementation for the\n",
        "best_theta = []\n",
        "best_loss = float('inf')\n",
        "for i in range(10):\n",
        "  print(f\"Test {i}\")\n",
        "  begin = time.time()\n",
        "  theta, loss = random_search(training_data_x, training_data_y)\n",
        "  end = time.time()\n",
        "\n",
        "  print(f\"Training Time: {end - begin}\")\n",
        "  print(f\"Best Iteration Theta: {theta}, Best Iteration Loss: {loss}\")\n",
        "\n",
        "  if(loss < best_loss):\n",
        "    best_loss = loss\n",
        "    best_theta = theta\n",
        "\n",
        "print(f\"Best Theta: {best_theta}, Best Loss: {best_loss}\")\n",
        "\n",
        "print(\"Testing:\")\n",
        "print(f\"Loss: {loss_RMSE(predict_multi(test_data_x, best_theta), test_data_y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6f2531",
      "metadata": {
        "id": "ba6f2531"
      },
      "source": [
        "TODO: describe here your experiments with the implementation for the random search\n",
        "\n",
        "---\n",
        "\n",
        "The implementation was a lot faster, as I didn't have to make multiple nested loops. However, my losses were astronomical, as it was hard to choose an interval that would give me values that fit the model.\n",
        "\n",
        "Additionally, while the actual testing ended up taking longer than grid search, each iteration of random search had 200 steps, so doing 10 tests would give me 2000 total steps- which is a lot more than my small grid search would yield at a similar level."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8cd1c2",
      "metadata": {
        "id": "7f8cd1c2"
      },
      "source": [
        "## P9: Use sklearn for linear regression in multiple variables\n",
        "Use ``sklearn.linear_model.LinearRegression`` to solve the same problem you previously solved using the grid search and random search.\n",
        "\n",
        "Compare the returned values with what you have achieved. Compare the parameters that had been found to the parameters you have found. Compare the speed.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "I realize that the model returned negative values for some of the thetas, so my implementations probably haven't been fitting very well because of that (I bounded all of my values at 0). Still, my implementation got as close as possible to sklearn's values, so I can't say my way wasn't effective at all.\n",
        "\n",
        "As with the simple linear regression, the sklearn library was both faster and more effective, taking less than a second and having the lowest loss yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f85619",
      "metadata": {
        "id": "e4f85619"
      },
      "outputs": [],
      "source": [
        "# TODO: implement here\n",
        "def linear_regression(training_data_features):\n",
        "  model = sk.linear_model.LinearRegression()\n",
        "\n",
        "  model.fit(training_data_features, training_data_y)\n",
        "\n",
        "  print(\"Optimal coefficients:\")\n",
        "  print(model.coef_)\n",
        "  print(f\"Optimal intercept: {model.intercept_}\")\n",
        "  return model.predict(test_data_x), test_data_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b7fbdca",
      "metadata": {
        "id": "5b7fbdca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29081e0e-43f1-4dad-c9f0-1dd3fce95a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effectiveness of Model:\n",
            "Optimal coefficients:\n",
            "[  2296.99015368  -5759.56172917 266061.05012341 -70557.66579111\n",
            "  23357.6031181  -85071.90074627 -12591.43761166]\n",
            "Optimal intercept: -181288.48931290733\n",
            "Time taken: 0.012474775314331055\n",
            "Loss: 448229.5203501845\n"
          ]
        }
      ],
      "source": [
        "# TODO: run experiments here.\n",
        "print(\"Effectiveness of Model:\")\n",
        "begin = time.time()\n",
        "predict, test_y = linear_regression(training_data_x)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Time taken: {end-begin}\")\n",
        "print(f\"Loss: {loss_RMSE_sk(test_y, predict)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3fb028",
      "metadata": {
        "id": "2f3fb028"
      },
      "source": [
        "TODO: describe in one paragraph your experiences with implementing the multiple variable linear regression.\n",
        "\n",
        "---\n",
        "\n",
        "Multiple variable linear regression isn't too different from simple variable linear regression- the difference comes with dealing with the x-values (which was represented with n-arrays, rather than single integers). All I changed was adding more values to the theta array, and using more loops (the grid_search in particular was a mess of nested for loops). Naturally, everything took longer to execute, because of course trying to minimize the loss of 8 different thetas is going to take longer than only finding 2. This would've been frustrating, but I kept my test values low because I didn't want to wait 15 minutes for it to finish."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5761a993",
      "metadata": {
        "id": "5761a993"
      },
      "source": [
        "TODO: describe in one paragraph your experiences with the data wrangling process.\n",
        "\n",
        "---\n",
        "\n",
        "Data wrangling in general was really annoying. For simple linear regression and multiple linear regression, I had a lot of NaN values- so I had to cut them out of the training values for x and y (I also did the same for the testing values just in case). Afterwards, the data worked well. I also had issues with understanding how the features in the multivariate example was put into the array, which led to a lot of index out of bound errors. Once I figured it out, though, it was very easy to continue."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ba6a81",
      "metadata": {
        "id": "22ba6a81"
      },
      "source": [
        "## P10: Explore other linear regression techniques\n",
        "\n",
        "Explore the use of other models provided from the sklearn library for linear regression.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
        "\n",
        "Try out two of them of your choice. Explain the results you obtained and compare them with other approaches.\n",
        "\n",
        "---\n",
        "\n",
        "As expected, using Ridge and Lasso regression models provided very similar results to the linear regression model. The values differed slightly- but not in a significant manner. The performance was also practically the same as they all executed in less than a second, though Lasso regression was the fastest by .001 and ridge regression was the slowest by .01. How interesting.\n",
        "\n",
        "Naturally, all of the models from sklearn outclassed mine, but that's because I chose values that weren't very optimal for my grids and random searches.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "def lasso_regression():\n",
        "  # Using Lasso module with alpha=0.1\n",
        "  model = linear_model.Lasso(alpha=0.1)\n",
        "  model.fit(training_data_x, training_data_y)\n",
        "  print(f\"Optimal intercept: {model.intercept_}\")\n",
        "  return model.predict(test_data_x), loss_RMSE_sk(test_data_y, model.predict(test_data_x)), model.coef_\n",
        "\n",
        "def ridge_regression():\n",
        "  # Using Ridge module with alpha=1.0\n",
        "  model = linear_model.Ridge(alpha=1.0)\n",
        "  model.fit(training_data_x, training_data_y)\n",
        "  print(f\"Optimal intercept: {model.intercept_}\")\n",
        "  return model.predict(test_data_x), loss_RMSE_sk(test_data_y, model.predict(test_data_x)), model.coef_"
      ],
      "metadata": {
        "id": "i5gl4GOAdbie"
      },
      "id": "i5gl4GOAdbie",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Lasso regression:\")\n",
        "begin = time.time()\n",
        "predict, loss, coef = lasso_regression()\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Time taken: {end-begin}\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Coefficients: {coef}\")\n",
        "\n",
        "print(\"Testing Ridge regression:\")\n",
        "begin = time.time()\n",
        "predict, loss, coef = ridge_regression()\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Time taken: {end-begin}\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Coefficients: {coef}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f0S7zP6ddkc",
        "outputId": "25c5bc7c-a7d2-46bd-f5ac-d1c58a26f857"
      },
      "id": "5f0S7zP6ddkc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Lasso regression:\n",
            "Optimal intercept: -181289.3405918791\n",
            "Time taken: 0.11123490333557129\n",
            "Loss: 448229.50824222417\n",
            "Coefficients: [  2296.99100275  -5759.27207167 266060.69308987 -70557.17298546\n",
            "  23357.03061385 -85069.85084401 -12590.86434857]\n",
            "Testing Ridge regression:\n",
            "Optimal intercept: -181315.31765617535\n",
            "Time taken: 0.02230381965637207\n",
            "Loss: 448228.0450497764\n",
            "Coefficients: [  2297.1469603   -5744.92830343 266029.35640635 -70532.23804046\n",
            "  23348.97072063 -84963.42116359 -12576.2997471 ]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}